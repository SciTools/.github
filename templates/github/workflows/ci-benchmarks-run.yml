# Use ASV to check for performance regressions, either:
#  - In the last 24 hours' commits.
#  - Introduced by this pull request.

name: benchmarks-run
run-name: Run benchmarks

on:
  schedule:
    # Runs every day at 23:00.
    - cron: "0 23 * * *"
  workflow_dispatch:
    inputs:
      first_commit:
        description: "First commit to benchmark (see bm_runner.py > Overnight)."
        required: false
        type: string
  pull_request:
  # TEMPLATING NOTE: could also consider `push` triggers if benchmarks don't
  #  take too long to run - this would replace the overnight scenario.

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  pre-checks:
    # This workflow supports two different scenarios (overnight and branch).
    #  The pre-checks job determines which scenario is being run.
    runs-on: ubuntu-latest
    if: github.repository == 'SciTools/REPONAME'
    outputs:
      overnight: ${{ steps.overnight.outputs.check }}
      branch: ${{ steps.branch.outputs.check }}
    steps:
      - uses: actions/checkout@v4
      # TEMPLATING NOTE: Iris also includes examples of label- and file-triggers.
      - id: overnight
        name: Check overnight scenario
        if: github.event_name != 'pull_request'
        run: echo "check=true" >> "$GITHUB_OUTPUT"
      - id: branch
        name: Check branch scenario
        if: github.event_name == 'pull_request'
        run: echo "check=true" >> "$GITHUB_OUTPUT"


  benchmark:
    runs-on: ubuntu-latest
    needs: pre-checks
    if: >
      needs.pre-checks.outputs.overnight == 'true' ||
      needs.pre-checks.outputs.branch == 'true'

    env:
      # Lets us manually bump the cache to rebuild
      ENV_CACHE_BUILD: "0"

    steps:
    # TEMPLATING NOTE: Iris also includes steps for handling iris-test-data.
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install run dependencies
        run: pip install asv  # Some repos also need Nox

      - name: Cache environment directories
        id: cache-env-dir
        uses: actions/cache@v4
        with:
          # TEMPLATING NOTE: consider other repo-specific cache directories.
          #  e.g: .nox
          path: |
            benchmarks/.asv/env
            $CONDA/pkgs
          key: ${{ runner.os }}-${{ hashFiles('requirements/') }}-${{ env.ENV_CACHE_BUILD }}

      - name: Benchmark this pull request
        # If the 'branch' condition(s) are met: use the bm_runner to compare
        #  the proposed merge with the base branch.
        if: needs.pre-checks.outputs.branch == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.number }}
        run: |
          benchmarks/bm_runner.py branch origin/${{ github.base_ref }}

      - name: Run overnight benchmarks
        # If the 'overnight' condition(s) are met: use the bm_runner to compare
        #  each of the last 24 hours' commits to their parents.
        id: overnight
        if: needs.pre-checks.outputs.overnight == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        # The first_commit argument allows a custom starting point - useful
        #  for manual re-running.
        run: |
          first_commit=${{ inputs.first_commit }}
          if [ "$first_commit" == "" ]
          then
            first_commit=$(git log --after="$(date -d "1 day ago" +"%Y-%m-%d") 23:00:00" --pretty=format:"%h" | tail -n 1)
          fi
          
          if [ "$first_commit" != "" ]
          then
            benchmarks/bm_runner.py overnight $first_commit
          fi

      - name: Warn of failure
        # The overnight run is not on a pull request, so a failure could go
        #  unnoticed without being actively advertised.
        if: >
          failure() &&
          steps.overnight.outcome == 'failure'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          title="Overnight benchmark workflow failed: \`${{ github.run_id }}\`"
          body="Generated by GHA run [\`${{github.run_id}}\`](https://github.com/${{github.repository}}/actions/runs/${{github.run_id}})"
          gh issue create --title "$title" --body "$body" --label "Bot" --label "Type: Performance" --repo $GITHUB_REPOSITORY

      - name: Upload any benchmark reports
        # Uploading enables more downstream processing e.g. posting a PR comment.
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_reports
          path: .github/workflows/benchmark_reports

      - name: Archive asv results
        # Store the raw ASV database(s) to help manual investigations.
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: asv-raw-results
          path: benchmarks/.asv/results
